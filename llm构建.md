# llmæž„å»º

## æž„å»º llama

å®‰è£…ä¾èµ–:

- CMake
- GCC
- CURL

å®‰è£…CURL:

```shell
sudo apt-get update
sudo apt-get install libcurl4-openssl-dev
```

æž„å»ºllama:

```shell
cmake -B build -DCMAKE_BUILD_TYPE=Debug
cmake --build build
```

## æ•°æ®å‡†å¤‡é˜¶æ®µ

[Skyformer](https://github.com/pkuzengqi/Skyformer?tab=readme-ov-file)

```shell
git clone https://github.com/pkuzengqi/Skyformer.git
cd Skyformer

python3 -m venv .venv
source .venv/bin/activate
pip install --upgrade pip
pip install 'tensorflow>=2.3.1' 'tensorflow-datasets>=4.0.1' 'tensorboard>=2.3.0'

wget https://storage.googleapis.com/long-range-arena/pathfinder_tfds.gz
gunzip pathfinder_tfds.gz
export _PATHFINDER_TFDS_PATH=~/CLionProjects/Skyformer/pathfinder_tfds
wget https://storage.googleapis.com/long-range-arena/lra_release.gz
mkdir -p data
tar -zxvf lra_release.gz -C data
mkdir -p data/lra_processed

cd src
python preprocess/create_pathfinder.py
python preprocess/create_listops.py
python preprocess/create_retrieval.py
python preprocess/create_text.py
python preprocess/create_cifar10.py # è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºçŽ°å†…å­˜åˆ†é…å¤±è´¥. é™åˆ¶è®­ç»ƒæ ·æœ¬æ•°é‡ä¸º10000000åŽæˆåŠŸ.
```

## æž„å»ºSATæ¨¡åž‹

[SAT](https://github.com/mlsys-lab-sogang/SAT?tab=readme-ov-file)

```shell
# å®‰è£…è™šæ‹ŸçŽ¯å¢ƒ

mkdir -p data
cp ../Skyformer/data/lra_processed/ data/ -r

sudo apt install python3.12-venv
python3 -m venv .venv
source .venv/bin/activate
# å®‰è£…ä¾èµ–
pip install tqdm
pip install numpy==1.26.4
pip install torch
pip install tensorboard
pip install requests
sh compile.sh
python main_learnable_skewness.py --mode train --task lra-image --random 1001 --name sat --sk 1.7 --ds 1.3 # è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºçŽ°GPUå†…å­˜ä¸è¶³çš„é—®é¢˜. å‡å°batch sizeåŽæˆåŠŸ.
python main_inference.py --mode eval --task lra-image --random 1001 --name sat
```

# å‚æ•°è¯´æ˜Žæ–‡æ¡£ï¼ˆSAT-Optimizationï¼‰

æœ¬é¡¹ç›®æ”¯æŒå¤šä¸ª LRA ä»»åŠ¡ï¼ˆå¦‚ `lra-image`, `lra-retrieval` ç­‰ï¼‰ï¼Œæ¨¡åž‹ç»“æž„ã€è®­ç»ƒæµç¨‹ã€ç¨€ç–åˆ‡æ¢é€»è¾‘å‡å¯é…ç½®ã€‚ä»¥ä¸‹æ˜¯å‘½ä»¤è¡Œå‚æ•°å’Œé…ç½®æ–‡ä»¶å‚æ•°çš„è¯¦ç»†è¯´æ˜Žã€‚

---

## ðŸ–¥ï¸ å‘½ä»¤è¡Œå‚æ•°

| å‚æ•°å             | ç¤ºä¾‹å€¼             | è¯´æ˜Ž                                    |
|-----------------|-----------------|---------------------------------------|
| `--mode`        | `train`, `eval` | è¿è¡Œæ¨¡å¼ï¼šè®­ç»ƒæˆ–è¯„ä¼°                            |
| `--task`        | `lra-image`     | æŒ‡å®šä»»åŠ¡åï¼Œå¯¹åº”é…ç½®æ–‡ä»¶ä¸­çš„ä»»åŠ¡é”®                     |
| `--random`      | `1001`          | éšæœºç§å­ï¼Œç”¨äºŽå¤çŽ°è®­ç»ƒå’Œå†³å®šè¾“å‡ºç›®å½•å                   |
| `--name`        | `sat`           | æ¨¡åž‹å‘½åå‰ç¼€ï¼Œå†³å®š checkpoint å’Œ `mat_lst` çš„ä¿å­˜å |
| `--sk`          | `1.7`           | ç¨€ç–åˆ‡æ¢åˆ¤æ®ï¼šæ³¨æ„åŠ› skewness é˜ˆå€¼                |
| `--ds`          | `1.3`           | ç¨€ç–åˆ‡æ¢åˆ¤æ®ï¼šæ³¨æ„åŠ› Frobenius è·ç¦»å˜åŒ–é˜ˆå€¼           |
| `--train_steps` | `5000`ï¼ˆå¯é€‰ï¼‰      | å¯è¦†ç›–é…ç½®ä¸­çš„ `num_train_steps`             |

---

## ðŸ§  é…ç½®ç»“æž„è¯´æ˜Žï¼ˆ`config.py`ï¼‰

æ¯ä¸ªä»»åŠ¡é…ç½®åˆ†ä¸ºä¸‰å—ï¼š`dataset`ã€`model`ã€`training`

---

### ðŸ“¦ dataset å­—æ®µ

| å‚æ•°      | è¯´æ˜Ž           |
|---------|--------------|
| `train` | è®­ç»ƒé›†æ ·æœ¬æ•°ï¼ˆç»Ÿè®¡ä¿¡æ¯ï¼‰ |
| `dev`   | éªŒè¯é›†æ ·æœ¬æ•°       |
| `test`  | æµ‹è¯•é›†æ ·æœ¬æ•°       |

---

### ðŸ§  model å­—æ®µï¼ˆæ¨¡åž‹ç»“æž„ï¼‰

| å‚æ•°å                      | ç¤ºä¾‹å€¼      | è¯´æ˜Ž                               |
|--------------------------|----------|----------------------------------|
| `learn_pos_emb`          | `True`   | æ˜¯å¦ä½¿ç”¨å¯å­¦ä¹ çš„ä½ç½®ç¼–ç                      |
| `tied_weights`           | `False`  | æ˜¯å¦å…±äº« encoder/decoder æƒé‡          |
| `embedding_dim`          | `64`     | è¾“å…¥åµŒå…¥ç»´åº¦                           |
| `transformer_dim`        | `64`     | transformer å±‚çš„é€šé“æ•°                |
| `transformer_hidden_dim` | `128`    | FFN éšè—å±‚ç»´åº¦                        |
| `head_dim`               | `32`     | æ¯ä¸ª attention head çš„ç»´åº¦            |
| `num_head`               | `2`      | attention head æ•°é‡                |
| `num_layers`             | `2`      | transformer å±‚æ•°                   |
| `vocab_size`             | `256`    | è¾“å…¥è¯è¡¨å¤§å°                           |
| `max_seq_len`            | `1024`   | æœ€å¤§è¾“å…¥åºåˆ—é•¿åº¦                         |
| `dropout_prob`           | `0.1`    | Dropout æ¦‚çŽ‡ï¼ˆéž attentionï¼‰          |
| `attention_dropout`      | `0.1`    | Attention dropout æ¦‚çŽ‡             |
| `pooling_mode`           | `"MEAN"` | è¾“å‡ºæ± åŒ–æ–¹å¼ï¼ˆ`MEAN`, `CLS`ï¼‰            |
| `num_classes`            | `10`     | è¾“å‡ºç±»åˆ«æ•°ï¼ˆåˆ†ç±»ä»»åŠ¡ï¼‰                      |
| `block_size`             | `32`     | ç¨€ç– attention ä¸­çš„ block å°ºå¯¸         |
| `batch_size`             | `256`    | æ¯å¼  GPU çš„ mini-batch å¤§å°           |
| `density`                | `0.05`   | ç¨€ç– attention ä¸­çš„ block ç¨ å¯†åº¦ï¼ˆè¶Šå°è¶Šç¨€ç–ï¼‰ |

---

### ðŸƒ training å­—æ®µï¼ˆè®­ç»ƒæµç¨‹ï¼‰

| å‚æ•°å                     | ç¤ºä¾‹å€¼        | è¯´æ˜Ž                                   |
|-------------------------|------------|--------------------------------------|
| `batch_size`            | `256`      | æ€»è®­ç»ƒ batch size                       |
| `learning_rate`         | `0.002`    | å­¦ä¹ çŽ‡                                  |
| `warmup`                | `175`      | warmup æ­¥æ•°ï¼ˆçº¿æ€§å¢žé•¿ï¼‰                      |
| `lr_decay`              | `"linear"` | å­¦ä¹ çŽ‡ä¸‹é™ç­–ç•¥ï¼ˆå¦‚çº¿æ€§ï¼‰                         |
| `weight_decay`          | `0`        | L2 æ­£åˆ™é¡¹ç³»æ•°                             |
| `eval_frequency`        | `500`      | æ¯å¤šå°‘æ­¥è¿›è¡Œä¸€æ¬¡éªŒè¯                           |
| `num_train_steps`       | `10000`    | æ€»è®­ç»ƒæ­¥æ•°                                |
| `num_init_steps`        | `0`        | åˆå§‹åŒ–é˜¶æ®µæ­¥æ•°ï¼ˆå¯å¿½ç•¥ï¼‰                         |
| `num_eval_steps`        | `20`       | æ¯æ¬¡éªŒè¯æ—¶è¿è¡Œå¤šå°‘ batch                      |
| `num_dense_train_steps` | `10`       | dense attention çš„è®­ç»ƒæ­¥æ•°ä¸Šé™              |
| `attn_loss_scale`       | `0.01`     | attention loss çš„ç¼©æ”¾å› å­                 |
| `skewness`              | `1.7`      | ç¨€ç–åˆ‡æ¢åˆ¤æ®ï¼šæ³¨æ„åŠ›åˆ†å¸ƒååº¦é˜ˆå€¼                     |
| `distance`              | `1.3`      | ç¨€ç–åˆ‡æ¢åˆ¤æ®ï¼šattention åˆ†å¸ƒå˜åŒ–çŽ‡ï¼ˆFrobenius è·ç¦»ï¼‰ |
| `patience`              | `10`       | æå‰åœæ­¢éªŒè¯é›†å‡†ç¡®åº¦æ— æå‡çš„å®¹å¿æ¬¡æ•°                   |

---

## ðŸ§¬ ç¨€ç– attention è‡ªåŠ¨åˆ‡æ¢æœºåˆ¶

æ¨¡åž‹ä¼šåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æ£€æµ‹ä»¥ä¸‹ä¸¤ä¸ªæŒ‡æ ‡ï¼š

- **skewnessï¼ˆååº¦ï¼‰**ï¼šæ³¨æ„åŠ›åˆ†å¸ƒæ˜¯å¦åç¦»å¹³å‡
- **Frobenius distance**ï¼šå½“å‰ä¸Žå‰ä¸€æ¬¡æ³¨æ„åŠ›çŸ©é˜µä¹‹é—´çš„å˜åŒ–é‡

å½“æ»¡è¶³ä»¥ä¸‹æ¡ä»¶æ—¶ä¼šåˆ‡æ¢åˆ° block-sparse attentionï¼š

```python
if skewness > sk_threshold and relative_distance_change > dist_threshold:
    transition = True
